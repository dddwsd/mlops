{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74b91b33",
   "metadata": {},
   "source": [
    "# Collision check\n",
    "\n",
    "tensorflow estimator model을 사용할때 feature에 tf.feature_column module이 들어가야 한다.\n",
    "\n",
    "보통 embedding(hashing(data))를 사용하는데, data의 unique count가 매우 큰 경우 이보다 작은 값으로 bucketsize를 정하기에 coliision이 발생할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bfbf374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.30677307 -1.0190516 ]\n",
      " [-0.30677307 -1.0190516 ]\n",
      " [-0.30677307 -1.0190516 ]\n",
      " [-0.30677307 -1.0190516 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.04094386 -0.17662054]\n",
      " [-0.26557332 -0.2745159 ]\n",
      " [-0.26557332 -0.2745159 ]\n",
      " [ 0.04094386 -0.17662054]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.18865938  0.0809349 ]\n",
      " [ 0.6760714   0.09676189]\n",
      " [ 0.6760714   0.09676189]\n",
      " [-0.18865938  0.0809349 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.5353973   0.63823575]\n",
      " [-0.12666304 -0.14882074]\n",
      " [ 0.48956296  0.4375769 ]\n",
      " [-0.5353973   0.63823575]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.04169198 -1.2398397 ]\n",
      " [ 0.25786075  0.73310757]\n",
      " [ 0.9352041  -0.0208841 ]\n",
      " [-0.43077955 -0.31218588]], shape=(4, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "# Fix seed\n",
    "tf.random.set_seed(825)\n",
    "\n",
    "data = {'keywords': ['1111', '2222', '3333', '4444']}\n",
    "\n",
    "# A utility method to show transromation from feature column\n",
    "def demo(feature_column, data):\n",
    "    feature_layer = tf.keras.layers.DenseFeatures(feature_column)\n",
    "    return feature_layer(data)\n",
    "\n",
    "def emb_hash(bucket_size):\n",
    "    keywords = tf.feature_column.categorical_column_with_hash_bucket(\"keywords\",\n",
    "    bucket_size)\n",
    "    emb = tf.feature_column.embedding_column(keywords,2)\n",
    "    return emb\n",
    "\n",
    "# bucket size = 1\n",
    "print(demo(emb_hash(1), data))\n",
    "# all output is same\n",
    "\n",
    "# bucket size = 2\n",
    "print(demo(emb_hash(2), data))\n",
    "# '1111' '4444' / '2222' '3333'\n",
    "\n",
    "# bucket size = 3\n",
    "print(demo(emb_hash(3), data))\n",
    "# '1111' '2222' '3333' / '4444'\n",
    "\n",
    "# bucket size = 4\n",
    "print(demo(emb_hash(4), data))\n",
    "# '1111' '4444' / '2222' '3333'\n",
    "\n",
    "# bucket size = 8\n",
    "print(demo(emb_hash(8), data))\n",
    "# '1111' '4444' / '2222' / '3333'\n",
    "\n",
    "# bucket size = 16\n",
    "print(demo(emb_hash(16), data))\n",
    "# all output is not same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dc74e1",
   "metadata": {},
   "source": [
    "이러한 collision을 막기 위한 방법으로 bloom embedding이라는 것이 있다.\n",
    "\n",
    "bloom embedding이란 동일한 데이터에 대해 blooming(복제)를 해서 여러 feature를 만들고\n",
    "\n",
    "이들을 다른 bucket size로 hashing한 다음 embedding하여 add 또는 concat함으로써 중복을 최소화하는 방식이다.\n",
    "\n",
    "위의 경우 '1111' '4444'가 동일하고 '2222' '3333'이 동일한 bucket size 2인 경우와\n",
    "\n",
    "'1111' '2222' '3333'이 동일하고 '4444' 혼자 다른 bucket size 3인 경우를 더하면\n",
    "\n",
    "아래와 같이 '1111' / '2222' '3333' / '4444' 끼리 동일한 값을 갖게 되고 collision이 줄어들었음을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81c51a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket2 = [[-0.7452543  -0.01533942]\n",
      " [ 0.46846437  0.15328027]\n",
      " [ 0.46846437  0.15328027]\n",
      " [-0.7452543  -0.01533942]]\n",
      "\n",
      "bucket3 = [[-1.09138    -0.28673676]\n",
      " [-1.09138    -0.28673676]\n",
      " [-1.09138    -0.28673676]\n",
      " [-0.01979477 -0.3555715 ]]\n",
      "\n",
      "Add bucket2 + bucket3 = [[-0.5869992   0.56720984]\n",
      " [ 0.6267195   0.73582953]\n",
      " [ 0.6267195   0.73582953]\n",
      " [-0.43409187 -1.3507265 ]]\n"
     ]
    }
   ],
   "source": [
    "# bucket size = 2\n",
    "bucket2 = demo(emb_hash(2), data)\n",
    "print(f'bucket2 = {bucket2}')\n",
    "# '1111' '4444' / '2222' '3333'\n",
    "\n",
    "# bucket size = 3\n",
    "bucket3 = demo(emb_hash(3), data)\n",
    "print(f'\\nbucket3 = {bucket3}')\n",
    "# '1111' '2222' '3333' / '4444'\n",
    "\n",
    "\n",
    "print(f'\\nAdd bucket2 + bucket3 = {bucket2 + bucket4}')\n",
    "# '1111' '4444' / '2222' '3333'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb4a17b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
